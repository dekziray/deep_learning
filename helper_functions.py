# -*- coding: utf-8 -*-
"""helper_functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K_6KbbEE11H2Nst09JeST2EUwuKe21YY
"""

import os
import tensorflow as tf
from collections import defaultdict
from shutil import copytree, rmtree, copy
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import itertools

# Creating helper functions

#1 download dataset and unzip
def get_data_extract(url):
  if "food-101" in os.listdir():
    print("Dataset exists in server")
  else:
    tf.keras.utils.get_file(
    'food-101.tar.gz',
    url,
    cache_subdir='/content',
    untar=True,
    )
    print("Dataset downloaded and unzipped!")



#2 Split data into train and test folders using filepath
def structure_data(filepath, src,dest):
  food_class_image = defaultdict(list)
  with open(filepath, 'r') as txt:
      paths = [read.strip() for read in txt.readlines()]
      for p in paths:
        food = p.split('/')
        food_class_image[food[0]].append(food[1] + '.jpg')

  for food in food_class_image.keys():
    print("\nCopying food images into ",food)
    if not os.path.exists(os.path.join(dest,food)):
      os.makedirs(os.path.join(dest,food))
    for i in food_class_image[food]:
      copy(os.path.join(src,food,i), os.path.join(dest,food,i))
  print("Copying Completed!")




#3  Plot loss and accuracy


# Plot the validation and training data separately
def plot_accloss_curves(history):
  loss = history.history['loss']
  val_loss = history.history['val_loss']
  accuracy = history.history['accuracy']
  val_accuracy = history.history['val_accuracy']
  epochs = range(len(history.history['loss']))
  # Plot loss
  plt.plot(epochs, loss, label='training_loss')
  plt.plot(epochs, val_loss, label='val_loss')
  plt.title('Loss')
  plt.xlabel('Epochs')
  plt.legend()

  # Plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label='training_accuracy')
  plt.plot(epochs, val_accuracy, label='val_accuracy')
  plt.title('Accuracy')
  plt.xlabel('Epochs')
  plt.legend();


def compare_history(original_history, new_history, initial_epochs):
    acc = original_history.history["accuracy"]
    loss = original_history.history["loss"]
    val_acc = original_history.history["val_accuracy"]
    val_loss = original_history.history["val_loss"]

    # combine original and new history
    total_acc = acc + new_history.history["accuracy"]
    total_loss = loss + new_history.history["loss"]
    total_val_acc = val_acc + new_history.history["val_accuracy"]
    total_val_loss = val_loss + new_history.history["val_loss"]
    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(total_acc, label='Training Accuracy')
    plt.plot(total_val_acc, label='Validation Accuracy')
    plt.plot([initial_epochs-1, initial_epochs-1],plt.ylim(), label='Fine-Tuning/Re-Training')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')
    plt.subplot(2, 1, 2)
    plt.plot(total_loss, label='Training Loss')
    plt.plot(total_val_loss, label='Validation Loss')
    plt.plot([initial_epochs-1, initial_epochs-1],plt.ylim(), label='Fine-Tuning/Re-Training')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()

def compare_three_history(original_history, new_history, new_history2, initial_epochs=5):
    acc = original_history.history["accuracy"]
    loss = original_history.history["loss"]
    val_acc = original_history.history["val_accuracy"]
    val_loss = original_history.history["val_loss"]

    # Combine the 3 history
    total_acc = acc + new_history.history["accuracy"] + new_history2.history["accuracy"]
    total_loss = loss + new_history.history["loss"] + new_history2.history["loss"]
    total_val_acc = val_acc + new_history.history["val_accuracy"] + new_history2.history["val_accuracy"]
    total_val_loss = val_loss + new_history.history["val_loss"] + new_history2.history["val_accuracy"]

    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(total_acc, label='Training Accuracy')
    plt.plot(total_val_acc, label='Validation Accuracy')
    plt.plot([initial_epochs-1, initial_epochs-1],plt.ylim(), label='Fine-Tuning/Re-Training')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(total_loss, label='Training Loss')
    plt.plot(total_val_loss, label='Validation Loss')
    plt.plot([initial_epochs-1, initial_epochs-1],plt.ylim(), label='Fine-Tuning/Re-Training')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()